# fly.toml app configuration file generated for ai-backends on 2025-08-21T13:18:03+08:00
#
# See https://fly.io/docs/reference/configuration/ for information about how to use this file.
#

app = 'ai-backends-test'
primary_region = 'sin'

[build]

# This is the service for our application
[[services]]
  internal_port = 3000
  processes = ['app']
  protocol = 'tcp'
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 0

  [services.concurrency]
    hard_limit = 25
    soft_limit = 20
    type = 'connections'

  [[services.ports]]
    handlers = ['http']
    port = 80
    force_https = true

  [[services.ports]]
    handlers = ['tls', 'http']
    port = 443

# This is the service for Ollama
[[services]]
  internal_port = 11434
  processes = ['app']
  protocol = 'tcp'
  
  [services.concurrency]
    hard_limit = 25
    soft_limit = 20
    type = 'connections'

  [[services.ports]]
    port = 11434

[[vm]]
  memory = '2gb'
  cpu_kind = 'shared'
  cpus = 1
